{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "\n",
    "import gpytorch\n",
    "from gpytorch.kernels import ScaleKernel, MaternKernel, RBFKernel\n",
    "from gpytorch.priors import GammaPrior\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "# Set device and global dtype\n",
    "device = \"cuda:0\"\n",
    "global_dtype = torch.float32\n",
    "\n",
    "# Ensure reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Add project source path\n",
    "notebook_dir = os.getcwd()\n",
    "src_path = os.path.abspath(os.path.join(notebook_dir, '../code'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# Import custom modules\n",
    "from gps import CholeskyGaussianProcess, IterativeGaussianProcess\n",
    "from util import train, eval, plot_gpr_results, fetch_uci_dataset, memory_dump\n",
    "from plotting import plot_gp_simple, plot_gp_sample, plot_gp_simple_regions\n",
    "\n",
    "# Enable autoreloading of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZE (45730, 10)\n",
      "Dataset loaded\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y = fetch_uci_dataset('protein',r\"C:\\Users\\fredw\\chris\\Research\\softki\\data\\uci_datasets\\uci_datasets\\protein\\data.csv\",train_frac=1/9,val_frac=4/9)\n",
    "train_x = train_x.to(device)\n",
    "train_y = train_y.to(device)\n",
    "test_x = test_x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = MaternKernel(lengthscale=1.0, variance=1.0)\n",
    "igp = IterativeGaussianProcess(kernel, noise=0.5, dtype=global_dtype, device=device,\n",
    "                               cg_tol=1e-2, cg_max_iter=10, warm_start=False, num_probes=0,\n",
    "                               preconditioner=\"identity\", trace_backend=\"Hutch\",\n",
    "                               verbose=False, track_iterations=True,pred_lanczos_rank=train_x.shape[0],compute_covariance=False)\n",
    "alpha = igp.fit(train_x, train_y)\n",
    "mean = igp.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_x, train_y, test_x, test_y, training_iterations=100, lr=0.1):\n",
    "    # optimizer = torch.optim.Adam([\n",
    "    #     {'params': model.kernel.parameters()}, \n",
    "    #     {'params': model.likelihood.parameters()}\n",
    "    # ], lr=lr)\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': model.kernel.parameters()}, \n",
    "        {'params': [model.noise.u]}  # Use raw_value instead of noise()\n",
    "    ], lr=lr)\n",
    "    # lr_sched = lambda epoch: 1.0  # Modify this function to change learning rate dynamically\n",
    "    # scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_sched)\n",
    "\n",
    "    runtime_log, mll_loss_log, test_rmse_log = [], [], []\n",
    "    for i in tqdm(range(training_iterations)):\n",
    "        start_time = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        model.fit(train_x, train_y)\n",
    "        loss = model.compute_mll(train_y)\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()  # Update the learning rate\n",
    "\n",
    "        # print(loss)\n",
    "        mean, covar = model.predict(test_x)\n",
    "        total_time = time.time() - start_time\n",
    "        runtime_log.append(total_time)\n",
    "        mll_loss_log.append(-loss.item())\n",
    "        \n",
    "        test_rmse = (torch.mean(torch.abs(mean - test_y))).item()\n",
    "        test_rmse_log.append(test_rmse)\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f'Iter {i+1}/{training_iterations}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return model, runtime_log, mll_loss_log, test_rmse_log, mean, covar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "softki",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
