{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : \n",
      "    The default C++ compiler could not be found on your system.\n",
      "    You need to either define the CXX environment variable or a symlink to the g++ command.\n",
      "    For example if g++-8 is the command you can do\n",
      "      import os\n",
      "      os.environ['CXX'] = 'g++-8'\n",
      "    \n",
      "[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode\n",
      "SIZE (16599, 19)\n",
      "Dataset loaded\n",
      "torch.Size([1659, 17])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "import time \n",
    "import gpytorch\n",
    "from gpytorch.functions import pivoted_cholesky\n",
    "\n",
    "from gpytorch.kernels import ScaleKernel, MaternKernel, RBFKernel\n",
    "from gpytorch.priors import GammaPrior\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "# Set device and global dtype\n",
    "device = \"cuda:0\"\n",
    "global_dtype = torch.float32\n",
    "\n",
    "# Ensure reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Add project source path\n",
    "notebook_dir = os.getcwd()\n",
    "src_path = os.path.abspath(os.path.join(notebook_dir, '../code'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# Import custom modules\n",
    "from gps import CholeskyGaussianProcess, IterativeGaussianProcess\n",
    "from util import train, eval, plot_gpr_results, fetch_uci_dataset, memory_dump\n",
    "from plotting import plot_gp_simple, plot_gp_sample, plot_gp_simple_regions\n",
    "\n",
    "# Enable autoreloading of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "train_x, train_y, test_x, test_y = fetch_uci_dataset('bike',r\"C:\\Users\\fredw\\chris\\Research\\softki\\data\\uci_datasets\\uci_datasets\\elevators\\data.csv\",train_frac=1/10,val_frac=0)\n",
    "train_x = train_x.to(device)\n",
    "train_y = train_y.to(device)\n",
    "test_x = test_x.to(device)\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2008.6356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2007.2786, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fredw\\chris\\Research\\RandomIterativeGP\\randomGP2\\code\\gps.py:336: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3687.)\n",
      "  quadratic = y.T @ self.alpha\n"
     ]
    }
   ],
   "source": [
    "base_kernel = MaternKernel(ard_num_dims=train_x.shape[-1], lengthscale_prior=GammaPrior(3.0, 6.0), nu=1.5)\n",
    "kernel = ScaleKernel(base_kernel, outputscale_prior=GammaPrior(2.0, 0.15)).to(device)\n",
    "\n",
    "cgp = CholeskyGaussianProcess(kernel=kernel, dtype=global_dtype, noise=0.4, device=device)\n",
    "\n",
    "\n",
    "base_kernel = MaternKernel(ard_num_dims=train_x.shape[-1], lengthscale_prior=GammaPrior(3.0, 6.0), nu=1.5)\n",
    "kernel = ScaleKernel(base_kernel, outputscale_prior=GammaPrior(2.0, 0.15)).to(device)\n",
    "\n",
    "igp = IterativeGaussianProcess(kernel=kernel, noise=0.4, dtype=global_dtype, device=device,\n",
    "                               cg_tol=1e-2, cg_max_iter=100, warm_start=False, num_probes=64,\n",
    "                               precon_type=\"identity\", trace_backend=\"Hutch\",\n",
    "                               verbose=False, track_iterations=False, \n",
    "                               pred_lanczos_rank=train_x.shape[0], compute_covariance=False)\n",
    "cgp.fit(train_x,train_y)\n",
    "igp.fit(train_x,train_y)\n",
    "\n",
    "print(cgp.compute_mll(train_y))\n",
    "print(igp.compute_mll(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n",
      "tensor(2079.6448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor(2079.1553, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "IGP MLL: -2079.1553, RMSE: 0.4352\n",
      "CGP MLL: -2079.6448, RMSE: 0.4203\n",
      "\n",
      "--- Gradient Comparison for parameter: raw_lengthscale ---\n",
      "Printing per-dimension gradients for ARD lengthscale parameter:\n",
      "\n",
      "Epoch 1:\n",
      "  Dimension 0: IGP = -39.3608, CGP = -55.4466, Relative Difference = 0.2901\n",
      "  Dimension 1: IGP = -37.3631, CGP = -53.7132, Relative Difference = 0.3044\n",
      "  Dimension 2: IGP = -37.5494, CGP = -52.3830, Relative Difference = 0.2832\n",
      "  Dimension 3: IGP = -23.9274, CGP = -31.6835, Relative Difference = 0.2448\n",
      "  Dimension 4: IGP = -33.2203, CGP = -48.0909, Relative Difference = 0.3092\n",
      "  Dimension 5: IGP = -22.0128, CGP = -31.0588, Relative Difference = 0.2913\n",
      "  Dimension 6: IGP = -26.7400, CGP = -37.1657, Relative Difference = 0.2805\n",
      "  Dimension 7: IGP = -29.0024, CGP = -39.7394, Relative Difference = 0.2702\n",
      "  Dimension 8: IGP = -20.0178, CGP = -27.5237, Relative Difference = 0.2727\n",
      "  Dimension 9: IGP = -9.5689, CGP = -13.0665, Relative Difference = 0.2677\n",
      "  Dimension 10: IGP = -8.7708, CGP = -12.1254, Relative Difference = 0.2767\n",
      "  Dimension 11: IGP = -8.7690, CGP = -12.1227, Relative Difference = 0.2766\n",
      "  Dimension 12: IGP = -8.4945, CGP = -11.7774, Relative Difference = 0.2787\n",
      "  Dimension 13: IGP = -20.1011, CGP = -22.5925, Relative Difference = 0.1103\n",
      "  Dimension 14: IGP = -0.0000, CGP = 0.0000, Relative Difference = 0.0000\n",
      "  Dimension 15: IGP = -7.3970, CGP = -7.7217, Relative Difference = 0.0421\n",
      "  Dimension 16: IGP = -0.0000, CGP = -0.0000, Relative Difference = 0.5302\n",
      "\n",
      "--- Gradient Comparison for parameter: noise ---\n",
      "Epoch\tIGP Gradient\tCGP Gradient\tRelative Difference\n",
      "1\t90.0300\t\t118.0184\t\t0.2372\n",
      "\n",
      "=== Loss and Error Metrics ===\n",
      "Epoch\tIGP MLL\t\tCGP MLL\t\tIGP RMSE\tCGP RMSE\n",
      "1\t-2079.1553\t\t-2079.6448\t\t0.4352\t\t0.4203\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "def train_and_compare_gradients(igp, cgp, train_x, train_y, test_x, test_y, epochs=1, lr=0.01):\n",
    "    # Define separate optimizers for both models\n",
    "    cgp_optimizer = torch.optim.Adam([\n",
    "        {'params': cgp.kernel.parameters()}, \n",
    "        {'params': [cgp.noise.u]}\n",
    "    ], lr=lr)\n",
    "    igp_optimizer = torch.optim.Adam([\n",
    "        {'params': igp.kernel.parameters()}, \n",
    "        {'params': [igp.noise.u]}\n",
    "    ], lr=lr)\n",
    "    \n",
    "    igp_grads = []\n",
    "    cgp_grads = []\n",
    "    igp_mll = []\n",
    "    cgp_mll = []\n",
    "    igp_rmse = []\n",
    "    cgp_rmse = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        # --- CGP Update ---\n",
    "        cgp_optimizer.zero_grad()\n",
    "        cgp.fit(train_x, train_y)\n",
    "        cgp_loss = cgp.compute_mll(train_y)\n",
    "        print(cgp_loss)\n",
    "        #print(cgp.kernel.outputscale)\n",
    "        cgp_loss.backward()\n",
    "        \n",
    "        # Collect gradients for CGP kernel and noise parameters\n",
    "        cgp_epoch_grads = {}\n",
    "        for name, param in cgp.kernel.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None:\n",
    "                cgp_epoch_grads[name] = param.grad.clone().cpu()\n",
    "        if cgp.noise.u.grad is not None:\n",
    "            cgp_epoch_grads[\"noise\"] = cgp.noise.u.grad.clone().cpu()\n",
    "        cgp_optimizer.step()\n",
    "        \n",
    "        # Save loss and error metrics (optional)\n",
    "        cgp_mll.append(-cgp_loss.item())\n",
    "        cgp_rmse.append(torch.mean(torch.abs(cgp.predict(test_x)[0].detach().cpu() - test_y)).item())\n",
    "        cgp_grads.append(cgp_epoch_grads)\n",
    "        \n",
    "        # --- IGP Update ---\n",
    "        igp.fit(train_x, train_y)\n",
    "        igp_loss = igp.compute_mll(train_y)\n",
    "        print(igp_loss)\n",
    "        #print(igp.kernel.outputscale)\n",
    "\n",
    "        igp_epoch_grads = igp.estimate_mll_gradient()\n",
    "        \n",
    "        # Convert gradients to CPU tensors or numpy arrays for consistency\n",
    "        igp_epoch_grads_cpu = {}\n",
    "        for key, grad in igp_epoch_grads.items():\n",
    "            igp_epoch_grads_cpu[key] = grad.clone().cpu() if isinstance(grad, torch.Tensor) else torch.tensor(grad, dtype=torch.float32)\n",
    "        \n",
    "        igp_optimizer.zero_grad()\n",
    "        for name, param in igp.kernel.named_parameters():\n",
    "            if param.requires_grad and name in igp_epoch_grads:\n",
    "                if param.grad is None:\n",
    "                    param.grad = -igp_epoch_grads[name].to(param.device)\n",
    "                else:\n",
    "                    param.grad.data = -igp_epoch_grads[name].to(param.device)\n",
    "        if \"noise\" in igp_epoch_grads:\n",
    "            if igp.noise.u.grad is None:\n",
    "                igp.noise.u.grad = -igp_epoch_grads[\"noise\"].to(igp.noise.u.device)\n",
    "            else:\n",
    "                igp.noise.u.grad.data = -igp_epoch_grads[\"noise\"].to(igp.noise.u.device)\n",
    "        igp_optimizer.step()\n",
    "        \n",
    "        igp_mll.append(-igp_loss.item())\n",
    "        igp_rmse.append(torch.mean(torch.abs(igp.predict(test_x)[0].detach().cpu() - test_y)).item())\n",
    "        igp_grads.append(igp_epoch_grads_cpu)\n",
    "        \n",
    "        print(f\"IGP MLL: {-igp_loss.item():.4f}, RMSE: {igp_rmse[-1]:.4f}\")\n",
    "        print(f\"CGP MLL: {-cgp_loss.item():.4f}, RMSE: {cgp_rmse[-1]:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        \"igp_grads\": igp_grads,\n",
    "        \"cgp_grads\": cgp_grads,\n",
    "        \"igp_mll\": igp_mll,\n",
    "        \"cgp_mll\": cgp_mll,\n",
    "        \"igp_rmse\": igp_rmse,\n",
    "        \"cgp_rmse\": cgp_rmse,\n",
    "        \"igp_final\": igp,\n",
    "        \"cgp_final\": cgp\n",
    "    }\n",
    "\n",
    "def print_gradient_comparison(results, param_names=None):\n",
    "    igp_grads = results[\"igp_grads\"]\n",
    "    cgp_grads = results[\"cgp_grads\"]\n",
    "    if param_names is None:\n",
    "        param_names = list(igp_grads[0].keys())\n",
    "    epochs = len(igp_grads)\n",
    "    \n",
    "    for param_name in param_names:\n",
    "        print(f\"\\n--- Gradient Comparison for parameter: {param_name} ---\")\n",
    "        igp_param_values = []\n",
    "        cgp_param_values = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            if param_name in igp_grads[epoch]:\n",
    "                igp_grad = igp_grads[epoch][param_name]\n",
    "                if isinstance(igp_grad, torch.Tensor):\n",
    "                    igp_values = igp_grad.detach().flatten().numpy()\n",
    "                else:\n",
    "                    igp_values = np.array([igp_grad])\n",
    "                igp_param_values.append(igp_values)\n",
    "            else:\n",
    "                igp_param_values.append(None)\n",
    "            \n",
    "            # For CGP, determine the matching key for the parameter\n",
    "            cgp_key = None\n",
    "            if param_name == \"noise\" and \"noise\" in cgp_grads[epoch]:\n",
    "                cgp_key = \"noise\"\n",
    "            else:\n",
    "                cgp_key = next((k for k in cgp_grads[epoch].keys() if param_name in k), None)\n",
    "            \n",
    "            if cgp_key:\n",
    "                cgp_grad = cgp_grads[epoch][cgp_key]\n",
    "                if isinstance(cgp_grad, torch.Tensor):\n",
    "                    cgp_values = cgp_grad.detach().flatten().numpy()\n",
    "                else:\n",
    "                    cgp_values = np.array([cgp_grad])\n",
    "                cgp_param_values.append(cgp_values)\n",
    "            else:\n",
    "                cgp_param_values.append(None)\n",
    "        \n",
    "        if \"lengthscale\" in param_name.lower():\n",
    "            print(\"Printing per-dimension gradients for ARD lengthscale parameter:\")\n",
    "            for epoch in range(epochs):\n",
    "                igp_vals = igp_param_values[epoch]\n",
    "                cgp_vals = cgp_param_values[epoch]\n",
    "                if igp_vals is not None and cgp_vals is not None:\n",
    "                    print(f\"\\nEpoch {epoch+1}:\")\n",
    "                    for idx, (i_val, c_val) in enumerate(zip(igp_vals, cgp_vals)):\n",
    "                        rel_diff = np.abs(i_val - c_val) / (np.abs(c_val) + 1e-10)\n",
    "                        print(f\"  Dimension {idx}: IGP = {i_val:.4f}, CGP = {c_val:.4f}, Relative Difference = {rel_diff:.4f}\")\n",
    "                else:\n",
    "                    print(f\"Epoch {epoch+1}: Missing data for one of the methods.\")\n",
    "        else:\n",
    "            is_scalar = all(val is not None and val.size == 1 for val in igp_param_values + cgp_param_values)\n",
    "            if is_scalar:\n",
    "                print(\"Epoch\\tIGP Gradient\\tCGP Gradient\\tRelative Difference\")\n",
    "                for epoch in range(epochs):\n",
    "                    igp_val = igp_param_values[epoch][0] if igp_param_values[epoch] is not None else None\n",
    "                    cgp_val = cgp_param_values[epoch][0] if cgp_param_values[epoch] is not None else None\n",
    "                    if igp_val is not None and cgp_val is not None:\n",
    "                        rel_diff = np.abs(igp_val - cgp_val) / (np.abs(cgp_val) + 1e-10)\n",
    "                        print(f\"{epoch+1}\\t{igp_val:.4f}\\t\\t{cgp_val:.4f}\\t\\t{rel_diff:.4f}\")\n",
    "                    else:\n",
    "                        print(f\"{epoch+1}\\tMissing data\")\n",
    "            else:\n",
    "                print(\"Non-scalar parameter gradients (displaying summary statistics per epoch):\")\n",
    "                for epoch in range(epochs):\n",
    "                    if igp_param_values[epoch] is not None and cgp_param_values[epoch] is not None:\n",
    "                        igp_mean = np.mean(igp_param_values[epoch])\n",
    "                        igp_std = np.std(igp_param_values[epoch])\n",
    "                        cgp_mean = np.mean(cgp_param_values[epoch])\n",
    "                        cgp_std = np.std(cgp_param_values[epoch])\n",
    "                        print(f\"Epoch {epoch+1}:\")\n",
    "                        print(f\"  IGP Gradient: mean = {igp_mean:.4f}, std = {igp_std:.4f}\")\n",
    "                        print(f\"  CGP Gradient: mean = {cgp_mean:.4f}, std = {cgp_std:.4f}\")\n",
    "                    else:\n",
    "                        print(f\"Epoch {epoch+1}: Missing data for one of the methods.\")\n",
    "    \n",
    "    print(\"\\n=== Loss and Error Metrics ===\")\n",
    "    print(\"Epoch\\tIGP MLL\\t\\tCGP MLL\\t\\tIGP RMSE\\tCGP RMSE\")\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"{epoch+1}\\t{results['igp_mll'][epoch]:.4f}\\t\\t{results['cgp_mll'][epoch]:.4f}\\t\\t\"\n",
    "              f\"{results['igp_rmse'][epoch]:.4f}\\t\\t{results['cgp_rmse'][epoch]:.4f}\")\n",
    "\n",
    "# Assuming train_x, train_y, test_x, test_y are already defined,\n",
    "# and that MaternKernel, GammaPrior, ScaleKernel, CholeskyGaussianProcess,\n",
    "# and IterativeGaussianProcess have been defined and imported appropriately.\n",
    "\n",
    "base_kernel = MaternKernel(ard_num_dims=train_x.shape[-1],\n",
    "                           lengthscale_prior=GammaPrior(3.0, 6.0),\n",
    "                           nu=1.5)\n",
    "# kernel = ScaleKernel(base_kernel).to(device) #outputscale_prior=GammaPrior(2.0, 0.15)\n",
    "cgp = CholeskyGaussianProcess(kernel=base_kernel, dtype=global_dtype, noise=0.4, device=device)\n",
    "\n",
    "base_kernel = MaternKernel(ard_num_dims=train_x.shape[-1],\n",
    "                           lengthscale_prior=GammaPrior(3.0, 6.0),\n",
    "                           nu=1.5)\n",
    "# kernel = ScaleKernel(base_kernel).to(device) #outputscale_prior=GammaPrior(2.0, 0.15)\n",
    "igp = IterativeGaussianProcess(kernel=base_kernel, noise=0.4, dtype=global_dtype, device=device,\n",
    "                               cg_tol=1e-3, cg_max_iter=100, warm_start=False, num_probes=64,\n",
    "                               precon_type=\"identity\", trace_backend=\"Hutch\",\n",
    "                               verbose=False, track_iterations=False, \n",
    "                               pred_lanczos_rank=train_x.shape[0], compute_covariance=False)\n",
    "\n",
    "results = train_and_compare_gradients(\n",
    "    igp=igp, \n",
    "    cgp=cgp, \n",
    "    train_x=train_x, \n",
    "    train_y=train_y, \n",
    "    test_x=test_x, \n",
    "    test_y=test_y, \n",
    "    epochs=1,\n",
    "    lr=0.01\n",
    ")\n",
    "\n",
    "print_gradient_comparison(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "softki",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
